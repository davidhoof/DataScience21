{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 1: Non-Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "We return to the MNIST data set on handwritten digits to compare non-linear classification algorithms ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the full MNIST data set contains 70k samples of digits 0-9 as 28*28 gray scale images (represented as 784 dim vectors)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at max/min value in the data\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.1: Cross-Validation and Support Vector Machines\n",
    "Train and optimize  C-SVM classifier on MNIST (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "* use a RBF kernel\n",
    "* use *random search* with cross-validation to find the best settings for *gamma* and *C* (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "* use max_iter in the SVM to avoid long training times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform,loguniform\n",
    "\n",
    "svm = SVC(gamma='auto',kernel='rbf',max_iter=100)\n",
    "\n",
    "distributions = dict(C=uniform(2,4),\n",
    "                      gamma=uniform(0.8, 1))\n",
    "clf = RandomizedSearchCV(svm, distributions, random_state=0,n_jobs=6)\n",
    "search = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.195254015709299, 'gamma': 1.5151893663724194}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.2: Pipelines and simple Neural Networks\n",
    "Split the MNIST data into  train- and test-sets and then train and evaluate a simple Multi Layer Perceptron (MLP) network. Since the non-linear activation functions of MLPs are sensitive to the scaling on the input (recall the *sigmoid* function), we need to scale all input values to [0,1] \n",
    "\n",
    "* combine all steps of your training in a SKL pipeline (https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "* use a SKL-scaler to scale the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* MLP Parameters: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "    * use a *SGD* solver\n",
    "    * use *tanh* as activation function\n",
    "    * compare networks with 1, 2 and 3 layers, use different numbers of neurons per layer\n",
    "    * adjust training parameters *alpha* (regularization) and *learning rate* - how sensitive is the model to these parameters?\n",
    "    * Hint: do not change all parameters at the same time, split into several experiments\n",
    "* How hard is it to find the best parameters? How many experiments would you need to find the best parameters?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP=make_pipeline(StandardScaler(), \n",
    "                       MLPClassifier(solver=\"sgd\",activation=\"tanh\",max_iter=300)\n",
    "                      )\n",
    "\n",
    "parameter_dist_1 = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [\n",
    "        (250,75,150),                                          \n",
    "        (125,100,),\n",
    "        (75,)\n",
    "    ]    \n",
    "}\n",
    "\n",
    "clf_hidden_layer = GridSearchCV(MLP, parameter_dist_1,n_jobs=6)\n",
    "search_hidden_layer = clf_hidden_layer.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1197.62055106,  779.17209044,  457.96134601]),\n",
       " 'std_fit_time': array([ 8.24785978, 29.46181064, 64.01808981]),\n",
       " 'mean_score_time': array([0.59640541, 0.31854677, 0.19807773]),\n",
       " 'std_score_time': array([0.03905095, 0.06067985, 0.05602251]),\n",
       " 'param_mlpclassifier__hidden_layer_sizes': masked_array(data=[(250, 75, 150), (125, 100), (75,)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'mlpclassifier__hidden_layer_sizes': (250, 75, 150)},\n",
       "  {'mlpclassifier__hidden_layer_sizes': (125, 100)},\n",
       "  {'mlpclassifier__hidden_layer_sizes': (75,)}],\n",
       " 'split0_test_score': array([0.96063492, 0.96222222, 0.95571429]),\n",
       " 'split1_test_score': array([0.95992063, 0.95857143, 0.96007937]),\n",
       " 'split2_test_score': array([0.96309524, 0.96071429, 0.95968254]),\n",
       " 'split3_test_score': array([0.95873016, 0.96126984, 0.95666667]),\n",
       " 'split4_test_score': array([0.96253968, 0.96246032, 0.95880952]),\n",
       " 'mean_test_score': array([0.96098413, 0.96104762, 0.95819048]),\n",
       " 'std_test_score': array([0.00162542, 0.0013905 , 0.00171061]),\n",
       " 'rank_test_score': array([2, 1, 3])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_hidden_layer.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "Der mean_test_score verändert sich nicht stark nach Layergröße. Dennoch erhöht sich die Laufzeit pro Layer quadratisch, aber erzielt kaum bessere Testergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameter_dist_2 = {\n",
    "    'mlpclassifier__alpha': [0.0001,0.001,0.01,0.1,1,2,4,8]  \n",
    "}\n",
    "\n",
    "clf_alpha = GridSearchCV(MLP, parameter_dist_2,n_jobs=6)\n",
    "search_alpha=clf_alpha.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([679.12808647, 670.87465792, 635.44919882, 674.28954568,\n",
       "        529.02818389, 375.73647251, 263.97652178, 181.37300878]),\n",
       " 'std_fit_time': array([61.70769071, 57.96803236, 47.62810899, 53.8713003 , 50.76709826,\n",
       "         3.3637014 , 11.10894855, 28.18452625]),\n",
       " 'mean_score_time': array([0.29141927, 0.26967778, 0.30079608, 0.29580746, 0.31356034,\n",
       "        0.30079861, 0.29760432, 0.16814475]),\n",
       " 'std_score_time': array([0.03288767, 0.01854586, 0.00861704, 0.01397227, 0.01562516,\n",
       "        0.01898472, 0.01916725, 0.0366852 ]),\n",
       " 'param_mlpclassifier__alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 2, 4, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'mlpclassifier__alpha': 0.0001},\n",
       "  {'mlpclassifier__alpha': 0.001},\n",
       "  {'mlpclassifier__alpha': 0.01},\n",
       "  {'mlpclassifier__alpha': 0.1},\n",
       "  {'mlpclassifier__alpha': 1},\n",
       "  {'mlpclassifier__alpha': 2},\n",
       "  {'mlpclassifier__alpha': 4},\n",
       "  {'mlpclassifier__alpha': 8}],\n",
       " 'split0_test_score': array([0.96055556, 0.96150794, 0.96142857, 0.96246032, 0.95579365,\n",
       "        0.94595238, 0.92992063, 0.91579365]),\n",
       " 'split1_test_score': array([0.96039683, 0.95912698, 0.96031746, 0.96134921, 0.95539683,\n",
       "        0.94357143, 0.92944444, 0.91484127]),\n",
       " 'split2_test_score': array([0.96198413, 0.96285714, 0.96293651, 0.96309524, 0.95674603,\n",
       "        0.94587302, 0.93039683, 0.91674603]),\n",
       " 'split3_test_score': array([0.96150794, 0.95920635, 0.9584127 , 0.96015873, 0.95333333,\n",
       "        0.94174603, 0.92761905, 0.9118254 ]),\n",
       " 'split4_test_score': array([0.95960317, 0.95984127, 0.96079365, 0.9618254 , 0.9568254 ,\n",
       "        0.94547619, 0.93103175, 0.91888889]),\n",
       " 'mean_test_score': array([0.96080952, 0.96050794, 0.96077778, 0.96177778, 0.95561905,\n",
       "        0.94452381, 0.92968254, 0.91561905]),\n",
       " 'std_test_score': array([0.00084351, 0.00145357, 0.00147576, 0.00100088, 0.00126726,\n",
       "        0.00163654, 0.00115775, 0.00232332]),\n",
       " 'rank_test_score': array([2, 4, 3, 1, 5, 6, 7, 8])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_alpha.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "Bei unterschiedlichen Alpha-Werten scheint das Modell nicht besonders sensitiv zu reagieren. Bei höheren alpha-Werten verringert sich die Laufzeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameter_dist_3 = {\n",
    "    'mlpclassifier__learning_rate': ['constant','adaptive','invscaling','power_t']\n",
    "}\n",
    "\n",
    "clf_learning_rate = GridSearchCV(MLP, parameter_dist_3,n_jobs=6)\n",
    "search_learning_rate=clf_learning_rate.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([650.66032395, 620.88554649, 175.66606541,   2.17857523]),\n",
       " 'std_fit_time': array([4.81906393e+01, 2.99445951e+01, 1.26026485e+01, 3.72036107e-02]),\n",
       " 'mean_score_time': array([0.27785811, 0.19467292, 0.27805552, 0.        ]),\n",
       " 'std_score_time': array([0.01439196, 0.05496089, 0.03636269, 0.        ]),\n",
       " 'param_mlpclassifier__learning_rate': masked_array(data=['constant', 'adaptive', 'invscaling', 'power_t'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'mlpclassifier__learning_rate': 'constant'},\n",
       "  {'mlpclassifier__learning_rate': 'adaptive'},\n",
       "  {'mlpclassifier__learning_rate': 'invscaling'},\n",
       "  {'mlpclassifier__learning_rate': 'power_t'}],\n",
       " 'split0_test_score': array([0.95936508, 0.95888889, 0.84428571,        nan]),\n",
       " 'split1_test_score': array([0.9581746 , 0.9602381 , 0.85484127,        nan]),\n",
       " 'split2_test_score': array([0.96007937, 0.96214286, 0.8497619 ,        nan]),\n",
       " 'split3_test_score': array([0.95944444, 0.95936508, 0.8481746 ,        nan]),\n",
       " 'split4_test_score': array([0.9602381 , 0.95920635, 0.84912698,        nan]),\n",
       " 'mean_test_score': array([0.95946032, 0.95996825, 0.8492381 ,        nan]),\n",
       " 'std_test_score': array([0.00072809, 0.00117568, 0.00338643,        nan]),\n",
       " 'rank_test_score': array([2, 1, 3, 4])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_learning_rate.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation\n",
    "constant und adaptive unterscheiden sich nicht stark. Beim invscaling reduziert sich der mittlere Testwert start. Dennoch benötigt er im Mean nicht solange Zeit, wie \n",
    "das konstante und adpative lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How hard is it to find the best parameters? How many experiments would you need to find the best parameters?\n",
    "Mit einem Gridsearch müssten alle Parameter- bzw. viele Parameterkombinationen durchgeprüft werden. Mit einem RandomSearch mit Cross Validierung können oft schneller Ergebnisse \n",
    "erzielt werden. Allerdings kann durch den Zufallsaspekt nur das lokale Optimum gefunden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
